{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/harsimar/harsimardata/fastmriorig/fastMRI/')\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_lightning import Trainer\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import RMSprop\n",
    "\n",
    "from common.args import Args\n",
    "from common.subsample import create_mask_for_mask_type\n",
    "from data import transforms\n",
    "from models.unet.unet_model import UnetModel\n",
    "import torchvision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#list(base_model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = models.resnet18(pretrained=True)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)        \n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)       \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)        \n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)        \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer0(input)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ResNetUNet(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def argi(args=None):\n",
    "    parser = Args()\n",
    "    parser.add_argument('--mode', choices=['train', 'test', 'challenge'], default='test')\n",
    "    parser.add_argument('--num-epochs', type=int, default=50, help='Number of training epochs')\n",
    "    parser.add_argument('--â€¦', type=int, default=1)\n",
    "    parser.add_argument('--nodes', type=int, default=1)\n",
    "    parser.add_argument('--exp-dir', type=pathlib.Path, default='experiments',\n",
    "                        help='Path where model and results should be saved')\n",
    "    parser.add_argument('--exp', type=str, help='Name of the experiment')\n",
    "    parser.add_argument('--checkpoint', type=pathlib.Path,\n",
    "                        help='Path to pre-trained model. Use with --mode {test,challenge}',default = '/home/harsimar/fastmriorig/fastMRI/epoch=47.ckpt')\n",
    "    parser.add_argument('--data_path', type=pathlib.Path, default='/home/harsimar/dataset/')\n",
    "    #parser = UnetMRIModel.add_model_specific_args(parser)\n",
    "    if args is not None:\n",
    "        parser.set_defaults(**args)\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from unetpp import NestedUNet\n",
    "from resnest import ResNet, Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnest50(pretrained=False, root='~/.encoding/models', **kwargs):\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], inchans=1,\n",
    "                   radix=2, groups=1, bottleneck_width=64,\n",
    "                   deep_stem=True, stem_width=32, avg_down=True,\n",
    "                   avd=True, avd_first=False, **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(torch.hub.load_state_dict_from_url(\n",
    "            resnest_model_urls['resnest50'], progress=True, check_hash=True))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "        \n",
    "model = resnest50(pretrained=False).to('cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): SplAtConv2d(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (rsoftmax): rSoftMax()\n",
       "      )\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): GlobalAvgPool2d()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A Convolutional Block that consists of two convolution layers each followed by\n",
    "    instance normalization, relu activation and dropout.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input.\n",
    "            out_chans (int): Number of channels in the output.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=3, padding=1),\n",
    "            nn.InstanceNorm2d(out_chans),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(drop_prob)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        return self.layers(input)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'ConvBlock(in_chans={self.in_chans}, out_chans={self.out_chans}, ' \\\n",
    "            f'drop_prob={self.drop_prob})'\n",
    "\n",
    "\n",
    "class UnetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch implementation of a U-Net model.\n",
    "\n",
    "    This is based on:\n",
    "        Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks\n",
    "        for biomedical image segmentation. In International Conference on Medical image\n",
    "        computing and computer-assisted intervention, pages 234â€“241. Springer, 2015.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chans, out_chans, chans, num_pool_layers, drop_prob):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_chans (int): Number of channels in the input to the U-Net model.\n",
    "            out_chans (int): Number of channels in the output to the U-Net model.\n",
    "            chans (int): Number of output channels of the first convolution layer.\n",
    "            num_pool_layers (int): Number of down-sampling and up-sampling layers.\n",
    "            drop_prob (float): Dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_chans = in_chans\n",
    "        self.out_chans = out_chans\n",
    "        self.chans = chans\n",
    "        self.num_pool_layers = num_pool_layers\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "        self.down_sample_layers = nn.ModuleList([ConvBlock(in_chans, chans, drop_prob)])\n",
    "        ch = chans\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.down_sample_layers += [ConvBlock(ch, ch * 2, drop_prob)]\n",
    "            ch *= 2\n",
    "        self.conv = ConvBlock(ch, ch, drop_prob)\n",
    "\n",
    "        self.up_sample_layers = nn.ModuleList()\n",
    "        for i in range(num_pool_layers - 1):\n",
    "            self.up_sample_layers += [ConvBlock(ch * 2, ch // 2, drop_prob)]\n",
    "            ch //= 2\n",
    "        self.up_sample_layers += [ConvBlock(ch * 2, ch, drop_prob)]\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(ch, ch // 2, kernel_size=1),\n",
    "            nn.Conv2d(ch // 2, out_chans, kernel_size=1),\n",
    "            nn.Conv2d(out_chans, out_chans, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor of shape [batch_size, self.in_chans, height, width]\n",
    "\n",
    "        Returns:\n",
    "            (torch.Tensor): Output tensor of shape [batch_size, self.out_chans, height, width]\n",
    "        \"\"\"\n",
    "        stack = []\n",
    "        output = input\n",
    "        # Apply down-sampling layers\n",
    "        for layer in self.down_sample_layers:\n",
    "            output = layer(output)\n",
    "            stack.append(output)\n",
    "            output = F.max_pool2d(output, kernel_size=2)\n",
    "\n",
    "        output = self.conv(output)\n",
    "\n",
    "        # Apply up-sampling layers\n",
    "        for layer in self.up_sample_layers:\n",
    "            output = F.interpolate(output, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "            output = torch.cat([output, stack.pop()], dim=1)\n",
    "            output = layer(output)\n",
    "        return self.conv2(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = UnetModel(\n",
    "        in_chans=1,\n",
    "        out_chans=1,\n",
    "        chans=32,\n",
    "        num_pool_layers=3,\n",
    "        drop_prob=0.0\n",
    "    ).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UnetModel(\n",
       "  (down_sample_layers): ModuleList(\n",
       "    (0): ConvBlock(in_chans=1, out_chans=32, drop_prob=0.0)\n",
       "    (1): ConvBlock(in_chans=32, out_chans=64, drop_prob=0.0)\n",
       "    (2): ConvBlock(in_chans=64, out_chans=128, drop_prob=0.0)\n",
       "  )\n",
       "  (conv): ConvBlock(in_chans=128, out_chans=128, drop_prob=0.0)\n",
       "  (up_sample_layers): ModuleList(\n",
       "    (0): ConvBlock(in_chans=256, out_chans=64, drop_prob=0.0)\n",
       "    (1): ConvBlock(in_chans=128, out_chans=32, drop_prob=0.0)\n",
       "    (2): ConvBlock(in_chans=64, out_chans=32, drop_prob=0.0)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (2): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def convrelu(in_channels, out_channels, kernel, padding):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class ResNetUNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.base_model = resnest50(pretrained=False)\n",
    "        \n",
    "        self.base_layers = list(base_model.children())                \n",
    "        \n",
    "        self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
    "        \n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        \n",
    "        self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)        \n",
    "        \n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)       \n",
    "        \n",
    "        self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)        \n",
    "        \n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        \n",
    "        self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)        \n",
    "        \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        \n",
    "        self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "        \n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)  \n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        \n",
    "        self.conv_original_size0 = convrelu(3, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        \n",
    "        self.conv_last = nn.Conv2d(64, n_class, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        \n",
    "        layer0 = self.layer0(input)            \n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        \n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    " \n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        \n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        \n",
    "        out = self.conv_last(x)        \n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final = ResNetUNet(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetUNet(\n",
       "  (base_model): ResNet(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    )\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (avd_layer): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): SplAtConv2d(\n",
       "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (rsoftmax): rSoftMax()\n",
       "        )\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): GlobalAvgPool2d()\n",
       "  )\n",
       "  (layer0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer0_1x1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer1): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layer1_1x1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2_1x1): Sequential(\n",
       "    (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3_1x1): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4_1x1): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (upsample): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  (conv_up3): Sequential(\n",
       "    (0): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up2): Sequential(\n",
       "    (0): Conv2d(640, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up1): Sequential(\n",
       "    (0): Conv2d(320, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_up0): Sequential(\n",
       "    (0): Conv2d(320, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size0): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size1): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_original_size2): Sequential(\n",
       "    (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_last): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary(model_final.to('cuda'), input_size=(1, 320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 160, 160]             288\n",
      "       BatchNorm2d-2         [-1, 32, 160, 160]              64\n",
      "              ReLU-3         [-1, 32, 160, 160]               0\n",
      "            Conv2d-4         [-1, 32, 160, 160]           9,216\n",
      "       BatchNorm2d-5         [-1, 32, 160, 160]              64\n",
      "              ReLU-6         [-1, 32, 160, 160]               0\n",
      "            Conv2d-7         [-1, 64, 160, 160]          18,432\n",
      "       BatchNorm2d-8         [-1, 64, 160, 160]             128\n",
      "              ReLU-9         [-1, 64, 160, 160]               0\n",
      "        MaxPool2d-10           [-1, 64, 80, 80]               0\n",
      "           Conv2d-11           [-1, 64, 80, 80]           4,096\n",
      "      BatchNorm2d-12           [-1, 64, 80, 80]             128\n",
      "             ReLU-13           [-1, 64, 80, 80]               0\n",
      "           Conv2d-14          [-1, 128, 80, 80]          36,864\n",
      "      BatchNorm2d-15          [-1, 128, 80, 80]             256\n",
      "             ReLU-16          [-1, 128, 80, 80]               0\n",
      "           Conv2d-17             [-1, 32, 1, 1]           2,080\n",
      "      BatchNorm2d-18             [-1, 32, 1, 1]              64\n",
      "             ReLU-19             [-1, 32, 1, 1]               0\n",
      "           Conv2d-20            [-1, 128, 1, 1]           4,224\n",
      "         rSoftMax-21                  [-1, 128]               0\n",
      "      SplAtConv2d-22           [-1, 64, 80, 80]               0\n",
      "           Conv2d-23          [-1, 256, 80, 80]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 80, 80]             512\n",
      "        AvgPool2d-25           [-1, 64, 80, 80]               0\n",
      "           Conv2d-26          [-1, 256, 80, 80]          16,384\n",
      "      BatchNorm2d-27          [-1, 256, 80, 80]             512\n",
      "             ReLU-28          [-1, 256, 80, 80]               0\n",
      "       Bottleneck-29          [-1, 256, 80, 80]               0\n",
      "           Conv2d-30           [-1, 64, 80, 80]          16,384\n",
      "      BatchNorm2d-31           [-1, 64, 80, 80]             128\n",
      "             ReLU-32           [-1, 64, 80, 80]               0\n",
      "           Conv2d-33          [-1, 128, 80, 80]          36,864\n",
      "      BatchNorm2d-34          [-1, 128, 80, 80]             256\n",
      "             ReLU-35          [-1, 128, 80, 80]               0\n",
      "           Conv2d-36             [-1, 32, 1, 1]           2,080\n",
      "      BatchNorm2d-37             [-1, 32, 1, 1]              64\n",
      "             ReLU-38             [-1, 32, 1, 1]               0\n",
      "           Conv2d-39            [-1, 128, 1, 1]           4,224\n",
      "         rSoftMax-40                  [-1, 128]               0\n",
      "      SplAtConv2d-41           [-1, 64, 80, 80]               0\n",
      "           Conv2d-42          [-1, 256, 80, 80]          16,384\n",
      "      BatchNorm2d-43          [-1, 256, 80, 80]             512\n",
      "             ReLU-44          [-1, 256, 80, 80]               0\n",
      "       Bottleneck-45          [-1, 256, 80, 80]               0\n",
      "           Conv2d-46           [-1, 64, 80, 80]          16,384\n",
      "      BatchNorm2d-47           [-1, 64, 80, 80]             128\n",
      "             ReLU-48           [-1, 64, 80, 80]               0\n",
      "           Conv2d-49          [-1, 128, 80, 80]          36,864\n",
      "      BatchNorm2d-50          [-1, 128, 80, 80]             256\n",
      "             ReLU-51          [-1, 128, 80, 80]               0\n",
      "           Conv2d-52             [-1, 32, 1, 1]           2,080\n",
      "      BatchNorm2d-53             [-1, 32, 1, 1]              64\n",
      "             ReLU-54             [-1, 32, 1, 1]               0\n",
      "           Conv2d-55            [-1, 128, 1, 1]           4,224\n",
      "         rSoftMax-56                  [-1, 128]               0\n",
      "      SplAtConv2d-57           [-1, 64, 80, 80]               0\n",
      "           Conv2d-58          [-1, 256, 80, 80]          16,384\n",
      "      BatchNorm2d-59          [-1, 256, 80, 80]             512\n",
      "             ReLU-60          [-1, 256, 80, 80]               0\n",
      "       Bottleneck-61          [-1, 256, 80, 80]               0\n",
      "           Conv2d-62          [-1, 128, 80, 80]          32,768\n",
      "      BatchNorm2d-63          [-1, 128, 80, 80]             256\n",
      "             ReLU-64          [-1, 128, 80, 80]               0\n",
      "           Conv2d-65          [-1, 256, 80, 80]         147,456\n",
      "      BatchNorm2d-66          [-1, 256, 80, 80]             512\n",
      "             ReLU-67          [-1, 256, 80, 80]               0\n",
      "           Conv2d-68             [-1, 64, 1, 1]           8,256\n",
      "      BatchNorm2d-69             [-1, 64, 1, 1]             128\n",
      "             ReLU-70             [-1, 64, 1, 1]               0\n",
      "           Conv2d-71            [-1, 256, 1, 1]          16,640\n",
      "         rSoftMax-72                  [-1, 256]               0\n",
      "      SplAtConv2d-73          [-1, 128, 80, 80]               0\n",
      "        AvgPool2d-74          [-1, 128, 40, 40]               0\n",
      "           Conv2d-75          [-1, 512, 40, 40]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 40, 40]           1,024\n",
      "        AvgPool2d-77          [-1, 256, 40, 40]               0\n",
      "           Conv2d-78          [-1, 512, 40, 40]         131,072\n",
      "      BatchNorm2d-79          [-1, 512, 40, 40]           1,024\n",
      "             ReLU-80          [-1, 512, 40, 40]               0\n",
      "       Bottleneck-81          [-1, 512, 40, 40]               0\n",
      "           Conv2d-82          [-1, 128, 40, 40]          65,536\n",
      "      BatchNorm2d-83          [-1, 128, 40, 40]             256\n",
      "             ReLU-84          [-1, 128, 40, 40]               0\n",
      "           Conv2d-85          [-1, 256, 40, 40]         147,456\n",
      "      BatchNorm2d-86          [-1, 256, 40, 40]             512\n",
      "             ReLU-87          [-1, 256, 40, 40]               0\n",
      "           Conv2d-88             [-1, 64, 1, 1]           8,256\n",
      "      BatchNorm2d-89             [-1, 64, 1, 1]             128\n",
      "             ReLU-90             [-1, 64, 1, 1]               0\n",
      "           Conv2d-91            [-1, 256, 1, 1]          16,640\n",
      "         rSoftMax-92                  [-1, 256]               0\n",
      "      SplAtConv2d-93          [-1, 128, 40, 40]               0\n",
      "           Conv2d-94          [-1, 512, 40, 40]          65,536\n",
      "      BatchNorm2d-95          [-1, 512, 40, 40]           1,024\n",
      "             ReLU-96          [-1, 512, 40, 40]               0\n",
      "       Bottleneck-97          [-1, 512, 40, 40]               0\n",
      "           Conv2d-98          [-1, 128, 40, 40]          65,536\n",
      "      BatchNorm2d-99          [-1, 128, 40, 40]             256\n",
      "            ReLU-100          [-1, 128, 40, 40]               0\n",
      "          Conv2d-101          [-1, 256, 40, 40]         147,456\n",
      "     BatchNorm2d-102          [-1, 256, 40, 40]             512\n",
      "            ReLU-103          [-1, 256, 40, 40]               0\n",
      "          Conv2d-104             [-1, 64, 1, 1]           8,256\n",
      "     BatchNorm2d-105             [-1, 64, 1, 1]             128\n",
      "            ReLU-106             [-1, 64, 1, 1]               0\n",
      "          Conv2d-107            [-1, 256, 1, 1]          16,640\n",
      "        rSoftMax-108                  [-1, 256]               0\n",
      "     SplAtConv2d-109          [-1, 128, 40, 40]               0\n",
      "          Conv2d-110          [-1, 512, 40, 40]          65,536\n",
      "     BatchNorm2d-111          [-1, 512, 40, 40]           1,024\n",
      "            ReLU-112          [-1, 512, 40, 40]               0\n",
      "      Bottleneck-113          [-1, 512, 40, 40]               0\n",
      "          Conv2d-114          [-1, 128, 40, 40]          65,536\n",
      "     BatchNorm2d-115          [-1, 128, 40, 40]             256\n",
      "            ReLU-116          [-1, 128, 40, 40]               0\n",
      "          Conv2d-117          [-1, 256, 40, 40]         147,456\n",
      "     BatchNorm2d-118          [-1, 256, 40, 40]             512\n",
      "            ReLU-119          [-1, 256, 40, 40]               0\n",
      "          Conv2d-120             [-1, 64, 1, 1]           8,256\n",
      "     BatchNorm2d-121             [-1, 64, 1, 1]             128\n",
      "            ReLU-122             [-1, 64, 1, 1]               0\n",
      "          Conv2d-123            [-1, 256, 1, 1]          16,640\n",
      "        rSoftMax-124                  [-1, 256]               0\n",
      "     SplAtConv2d-125          [-1, 128, 40, 40]               0\n",
      "          Conv2d-126          [-1, 512, 40, 40]          65,536\n",
      "     BatchNorm2d-127          [-1, 512, 40, 40]           1,024\n",
      "            ReLU-128          [-1, 512, 40, 40]               0\n",
      "      Bottleneck-129          [-1, 512, 40, 40]               0\n",
      "          Conv2d-130          [-1, 256, 40, 40]         131,072\n",
      "     BatchNorm2d-131          [-1, 256, 40, 40]             512\n",
      "            ReLU-132          [-1, 256, 40, 40]               0\n",
      "          Conv2d-133          [-1, 512, 40, 40]         589,824\n",
      "     BatchNorm2d-134          [-1, 512, 40, 40]           1,024\n",
      "            ReLU-135          [-1, 512, 40, 40]               0\n",
      "          Conv2d-136            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-137            [-1, 128, 1, 1]             256\n",
      "            ReLU-138            [-1, 128, 1, 1]               0\n",
      "          Conv2d-139            [-1, 512, 1, 1]          66,048\n",
      "        rSoftMax-140                  [-1, 512]               0\n",
      "     SplAtConv2d-141          [-1, 256, 40, 40]               0\n",
      "       AvgPool2d-142          [-1, 256, 20, 20]               0\n",
      "          Conv2d-143         [-1, 1024, 20, 20]         262,144\n",
      "     BatchNorm2d-144         [-1, 1024, 20, 20]           2,048\n",
      "       AvgPool2d-145          [-1, 512, 20, 20]               0\n",
      "          Conv2d-146         [-1, 1024, 20, 20]         524,288\n",
      "     BatchNorm2d-147         [-1, 1024, 20, 20]           2,048\n",
      "            ReLU-148         [-1, 1024, 20, 20]               0\n",
      "      Bottleneck-149         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-150          [-1, 256, 20, 20]         262,144\n",
      "     BatchNorm2d-151          [-1, 256, 20, 20]             512\n",
      "            ReLU-152          [-1, 256, 20, 20]               0\n",
      "          Conv2d-153          [-1, 512, 20, 20]         589,824\n",
      "     BatchNorm2d-154          [-1, 512, 20, 20]           1,024\n",
      "            ReLU-155          [-1, 512, 20, 20]               0\n",
      "          Conv2d-156            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-157            [-1, 128, 1, 1]             256\n",
      "            ReLU-158            [-1, 128, 1, 1]               0\n",
      "          Conv2d-159            [-1, 512, 1, 1]          66,048\n",
      "        rSoftMax-160                  [-1, 512]               0\n",
      "     SplAtConv2d-161          [-1, 256, 20, 20]               0\n",
      "          Conv2d-162         [-1, 1024, 20, 20]         262,144\n",
      "     BatchNorm2d-163         [-1, 1024, 20, 20]           2,048\n",
      "            ReLU-164         [-1, 1024, 20, 20]               0\n",
      "      Bottleneck-165         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-166          [-1, 256, 20, 20]         262,144\n",
      "     BatchNorm2d-167          [-1, 256, 20, 20]             512\n",
      "            ReLU-168          [-1, 256, 20, 20]               0\n",
      "          Conv2d-169          [-1, 512, 20, 20]         589,824\n",
      "     BatchNorm2d-170          [-1, 512, 20, 20]           1,024\n",
      "            ReLU-171          [-1, 512, 20, 20]               0\n",
      "          Conv2d-172            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-173            [-1, 128, 1, 1]             256\n",
      "            ReLU-174            [-1, 128, 1, 1]               0\n",
      "          Conv2d-175            [-1, 512, 1, 1]          66,048\n",
      "        rSoftMax-176                  [-1, 512]               0\n",
      "     SplAtConv2d-177          [-1, 256, 20, 20]               0\n",
      "          Conv2d-178         [-1, 1024, 20, 20]         262,144\n",
      "     BatchNorm2d-179         [-1, 1024, 20, 20]           2,048\n",
      "            ReLU-180         [-1, 1024, 20, 20]               0\n",
      "      Bottleneck-181         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-182          [-1, 256, 20, 20]         262,144\n",
      "     BatchNorm2d-183          [-1, 256, 20, 20]             512\n",
      "            ReLU-184          [-1, 256, 20, 20]               0\n",
      "          Conv2d-185          [-1, 512, 20, 20]         589,824\n",
      "     BatchNorm2d-186          [-1, 512, 20, 20]           1,024\n",
      "            ReLU-187          [-1, 512, 20, 20]               0\n",
      "          Conv2d-188            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-189            [-1, 128, 1, 1]             256\n",
      "            ReLU-190            [-1, 128, 1, 1]               0\n",
      "          Conv2d-191            [-1, 512, 1, 1]          66,048\n",
      "        rSoftMax-192                  [-1, 512]               0\n",
      "     SplAtConv2d-193          [-1, 256, 20, 20]               0\n",
      "          Conv2d-194         [-1, 1024, 20, 20]         262,144\n",
      "     BatchNorm2d-195         [-1, 1024, 20, 20]           2,048\n",
      "            ReLU-196         [-1, 1024, 20, 20]               0\n",
      "      Bottleneck-197         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-198          [-1, 256, 20, 20]         262,144\n",
      "     BatchNorm2d-199          [-1, 256, 20, 20]             512\n",
      "            ReLU-200          [-1, 256, 20, 20]               0\n",
      "          Conv2d-201          [-1, 512, 20, 20]         589,824\n",
      "     BatchNorm2d-202          [-1, 512, 20, 20]           1,024\n",
      "            ReLU-203          [-1, 512, 20, 20]               0\n",
      "          Conv2d-204            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-205            [-1, 128, 1, 1]             256\n",
      "            ReLU-206            [-1, 128, 1, 1]               0\n",
      "          Conv2d-207            [-1, 512, 1, 1]          66,048\n",
      "        rSoftMax-208                  [-1, 512]               0\n",
      "     SplAtConv2d-209          [-1, 256, 20, 20]               0\n",
      "          Conv2d-210         [-1, 1024, 20, 20]         262,144\n",
      "     BatchNorm2d-211         [-1, 1024, 20, 20]           2,048\n",
      "            ReLU-212         [-1, 1024, 20, 20]               0\n",
      "      Bottleneck-213         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-214          [-1, 256, 20, 20]         262,144\n",
      "     BatchNorm2d-215          [-1, 256, 20, 20]             512\n",
      "            ReLU-216          [-1, 256, 20, 20]               0\n",
      "          Conv2d-217          [-1, 512, 20, 20]         589,824\n",
      "     BatchNorm2d-218          [-1, 512, 20, 20]           1,024\n",
      "            ReLU-219          [-1, 512, 20, 20]               0\n",
      "          Conv2d-220            [-1, 128, 1, 1]          32,896\n",
      "     BatchNorm2d-221            [-1, 128, 1, 1]             256\n",
      "            ReLU-222            [-1, 128, 1, 1]               0\n",
      "          Conv2d-223            [-1, 512, 1, 1]          66,048\n",
      "        rSoftMax-224                  [-1, 512]               0\n",
      "     SplAtConv2d-225          [-1, 256, 20, 20]               0\n",
      "          Conv2d-226         [-1, 1024, 20, 20]         262,144\n",
      "     BatchNorm2d-227         [-1, 1024, 20, 20]           2,048\n",
      "            ReLU-228         [-1, 1024, 20, 20]               0\n",
      "      Bottleneck-229         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-230          [-1, 512, 20, 20]         524,288\n",
      "     BatchNorm2d-231          [-1, 512, 20, 20]           1,024\n",
      "            ReLU-232          [-1, 512, 20, 20]               0\n",
      "          Conv2d-233         [-1, 1024, 20, 20]       2,359,296\n",
      "     BatchNorm2d-234         [-1, 1024, 20, 20]           2,048\n",
      "            ReLU-235         [-1, 1024, 20, 20]               0\n",
      "          Conv2d-236            [-1, 256, 1, 1]         131,328\n",
      "     BatchNorm2d-237            [-1, 256, 1, 1]             512\n",
      "            ReLU-238            [-1, 256, 1, 1]               0\n",
      "          Conv2d-239           [-1, 1024, 1, 1]         263,168\n",
      "        rSoftMax-240                 [-1, 1024]               0\n",
      "     SplAtConv2d-241          [-1, 512, 20, 20]               0\n",
      "       AvgPool2d-242          [-1, 512, 10, 10]               0\n",
      "          Conv2d-243         [-1, 2048, 10, 10]       1,048,576\n",
      "     BatchNorm2d-244         [-1, 2048, 10, 10]           4,096\n",
      "       AvgPool2d-245         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-246         [-1, 2048, 10, 10]       2,097,152\n",
      "     BatchNorm2d-247         [-1, 2048, 10, 10]           4,096\n",
      "            ReLU-248         [-1, 2048, 10, 10]               0\n",
      "      Bottleneck-249         [-1, 2048, 10, 10]               0\n",
      "          Conv2d-250          [-1, 512, 10, 10]       1,048,576\n",
      "     BatchNorm2d-251          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-252          [-1, 512, 10, 10]               0\n",
      "          Conv2d-253         [-1, 1024, 10, 10]       2,359,296\n",
      "     BatchNorm2d-254         [-1, 1024, 10, 10]           2,048\n",
      "            ReLU-255         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-256            [-1, 256, 1, 1]         131,328\n",
      "     BatchNorm2d-257            [-1, 256, 1, 1]             512\n",
      "            ReLU-258            [-1, 256, 1, 1]               0\n",
      "          Conv2d-259           [-1, 1024, 1, 1]         263,168\n",
      "        rSoftMax-260                 [-1, 1024]               0\n",
      "     SplAtConv2d-261          [-1, 512, 10, 10]               0\n",
      "          Conv2d-262         [-1, 2048, 10, 10]       1,048,576\n",
      "     BatchNorm2d-263         [-1, 2048, 10, 10]           4,096\n",
      "            ReLU-264         [-1, 2048, 10, 10]               0\n",
      "      Bottleneck-265         [-1, 2048, 10, 10]               0\n",
      "          Conv2d-266          [-1, 512, 10, 10]       1,048,576\n",
      "     BatchNorm2d-267          [-1, 512, 10, 10]           1,024\n",
      "            ReLU-268          [-1, 512, 10, 10]               0\n",
      "          Conv2d-269         [-1, 1024, 10, 10]       2,359,296\n",
      "     BatchNorm2d-270         [-1, 1024, 10, 10]           2,048\n",
      "            ReLU-271         [-1, 1024, 10, 10]               0\n",
      "          Conv2d-272            [-1, 256, 1, 1]         131,328\n",
      "     BatchNorm2d-273            [-1, 256, 1, 1]             512\n",
      "            ReLU-274            [-1, 256, 1, 1]               0\n",
      "          Conv2d-275           [-1, 1024, 1, 1]         263,168\n",
      "        rSoftMax-276                 [-1, 1024]               0\n",
      "     SplAtConv2d-277          [-1, 512, 10, 10]               0\n",
      "          Conv2d-278         [-1, 2048, 10, 10]       1,048,576\n",
      "     BatchNorm2d-279         [-1, 2048, 10, 10]           4,096\n",
      "            ReLU-280         [-1, 2048, 10, 10]               0\n",
      "      Bottleneck-281         [-1, 2048, 10, 10]               0\n",
      " GlobalAvgPool2d-282                 [-1, 2048]               0\n",
      "================================================================\n",
      "Total params: 25,433,664\n",
      "Trainable params: 25,433,664\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.39\n",
      "Forward/backward pass size (MB): 777.13\n",
      "Params size (MB): 97.02\n",
      "Estimated Total Size (MB): 874.54\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.to('cuda'),input_size=(1, 320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_mod = resnest50(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_layers = list(base_mod.children())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU(inplace=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_layers[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_layers[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Bottleneck(\n",
       "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): SplAtConv2d(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (rsoftmax): rSoftMax()\n",
       "    )\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (downsample): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
       "      (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (1): Bottleneck(\n",
       "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): SplAtConv2d(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (rsoftmax): rSoftMax()\n",
       "    )\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (2): Bottleneck(\n",
       "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): SplAtConv2d(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
       "      (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (rsoftmax): rSoftMax()\n",
       "    )\n",
       "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_layers[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fastai\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "from torchvision.models import vgg16_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torchvision.models.resnet.resnet18(pretrained=False, progress=True, **kwargs)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arch = models.resnet18\n",
    "arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.models.unet import DynamicUnet\n",
    "from fastai.vision.models.unet import UnetBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'function' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-70fd39c51379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDynamicUnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/harsimar/lib/python3.6/site-packages/fastai/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pre_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0mold_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_init\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/harsimar/lib/python3.6/site-packages/fastai/vision/models/unet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, encoder, n_classes, img_size, blur, blur_final, self_attention, y_range, last_cross, bottle, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                  last_cross:bool=True, bottle:bool=False, **kwargs):\n\u001b[1;32m     42\u001b[0m         \u001b[0mimsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0msfs_szs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0msfs_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_sfs_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msfs_szs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msfs_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/harsimar/lib/python3.6/site-packages/fastai/callbacks/hooks.py\u001b[0m in \u001b[0;36mmodel_sizes\u001b[0;34m(m, size)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmodel_sizes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSizes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mHooks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;34m\"Pass a dummy input through the model `m` to get the various sizes of activations.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mhook_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdummy_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstored\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/harsimar/lib/python3.6/site-packages/fastai/callbacks/hooks.py\u001b[0m in \u001b[0;36mhook_outputs\u001b[0;34m(modules, detach, grad)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhook_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mHooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;34m\"Return `Hooks` that store activations of all `modules` in `self.stored`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_hook_inner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_forward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHookCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLearnerCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/harsimar/lib/python3.6/site-packages/fastai/callbacks/hooks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ms, hook_func, is_forward, detach)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;34m\"Create several hooks on the modules in `ms` with `hook_func`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mCollection\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_func\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mHookFunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_forward\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mHook\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'function' object is not iterable"
     ]
    }
   ],
   "source": [
    "DynamicUnet(encoder = models.resnet18, n_classes = 1 , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import *\n",
    "from fastai.layers import *\n",
    "from fastai.callbacks.hooks import *\n",
    "\n",
    "__all__ = ['DynamicUnet', 'UnetBlock']\n",
    "\n",
    "def _get_sfs_idxs(sizes:Sizes) -> List[int]:\n",
    "    \"Get the indexes of the layers where the size of the activation changes.\"\n",
    "    feature_szs = [size[-1] for size in sizes]\n",
    "    sfs_idxs = list(np.where(np.array(feature_szs[:-1]) != np.array(feature_szs[1:]))[0])\n",
    "    if feature_szs[0] != feature_szs[1]: sfs_idxs = [0] + sfs_idxs\n",
    "    return sfs_idxs\n",
    "\n",
    "class DynamicUnet(SequentialEx):\n",
    "    \"Create a U-Net from a given architecture.\"\n",
    "    def __init__(self, encoder:nn.Module, n_classes:int, img_size:Tuple[int,int]=(256,256), blur:bool=False, blur_final=True, self_attention:bool=False,\n",
    "                 y_range:Optional[Tuple[float,float]]=None,\n",
    "                 last_cross:bool=True, bottle:bool=False, **kwargs):\n",
    "        imsize = img_size\n",
    "        print(img_size)\n",
    "        sfs_szs = model_sizes(encoder, size=imsize)\n",
    "        sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\n",
    "        self.sfs = hook_outputs([encoder[i] for i in sfs_idxs], detach=False)\n",
    "        x = dummy_eval(encoder, imsize).detach()\n",
    "\n",
    "        ni = sfs_szs[-1][1]\n",
    "        middle_conv = nn.Sequential(conv_layer(ni, ni*2, **kwargs),\n",
    "                                    conv_layer(ni*2, ni, **kwargs)).eval()\n",
    "        x = middle_conv(x)\n",
    "        layers = [encoder, batchnorm_2d(ni), nn.ReLU(), middle_conv]\n",
    "\n",
    "        for i,idx in enumerate(sfs_idxs):\n",
    "            not_final = i!=len(sfs_idxs)-1\n",
    "            up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\n",
    "            do_blur = blur and (not_final or blur_final)\n",
    "            sa = self_attention and (i==len(sfs_idxs)-3)\n",
    "            unet_block = UnetBlock(up_in_c, x_in_c, self.sfs[i], final_div=not_final, blur=do_blur, self_attention=sa,\n",
    "                                   **kwargs).eval()\n",
    "            layers.append(unet_block)\n",
    "            x = unet_block(x)\n",
    "\n",
    "        ni = x.shape[1]\n",
    "        if imsize != sfs_szs[0][-2:]: layers.append(PixelShuffle_ICNR(ni, **kwargs))\n",
    "        x = PixelShuffle_ICNR(ni)(x)\n",
    "        if imsize != x.shape[-2:]: layers.append(Lambda(lambda x: F.interpolate(x, imsize, mode='nearest')))\n",
    "        if last_cross:\n",
    "            layers.append(MergeLayer(dense=True))\n",
    "            ni += in_channels(encoder)\n",
    "            layers.append(res_block(ni, bottle=bottle, **kwargs))\n",
    "        layers += [conv_layer(ni, n_classes, ks=1, use_activ=False, **kwargs)]\n",
    "        if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "        super().__init__(*layers)\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, \"sfs\"): self.sfs.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DynamicUnet(encoder = model,n_classes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.models.efficientnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class da():\n",
    "     def __init__(self):\n",
    "        self.c = 1\n",
    "data = da()\n",
    "efficientmodel = EfficientNetB1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(320,320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([320, 320])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 320, 320])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn([10,320,320])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 320, 320])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = torch.randn([18,102400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 102400])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 102400])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.view(a.size(0), -1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 320, 320])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = b.view(b.size(0), 320, 320)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EfficientNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c0fcd929653c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEfficientNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"efficientnet-b0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvprop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'EfficientNet' is not defined"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained(\"efficientnet-b0\", advprop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "model = EfficientNet.from_name('efficientnet-b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.2, inplace=False)\n",
       "  (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EfficientNet' object has no attribute '_change_in_channels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a1bbe61ad74d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_change_in_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/harsimar/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EfficientNet' object has no attribute '_change_in_channels'"
     ]
    }
   ],
   "source": [
    "model._change_in_channels(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         ZeroPad2d-1          [-1, 3, 321, 321]               0\n",
      "Conv2dStaticSamePadding-2         [-1, 32, 160, 160]             864\n",
      "       BatchNorm2d-3         [-1, 32, 160, 160]              64\n",
      "MemoryEfficientSwish-4         [-1, 32, 160, 160]               0\n",
      "         ZeroPad2d-5         [-1, 32, 162, 162]               0\n",
      "Conv2dStaticSamePadding-6         [-1, 32, 160, 160]             288\n",
      "       BatchNorm2d-7         [-1, 32, 160, 160]              64\n",
      "MemoryEfficientSwish-8         [-1, 32, 160, 160]               0\n",
      "          Identity-9             [-1, 32, 1, 1]               0\n",
      "Conv2dStaticSamePadding-10              [-1, 8, 1, 1]             264\n",
      "MemoryEfficientSwish-11              [-1, 8, 1, 1]               0\n",
      "         Identity-12              [-1, 8, 1, 1]               0\n",
      "Conv2dStaticSamePadding-13             [-1, 32, 1, 1]             288\n",
      "         Identity-14         [-1, 32, 160, 160]               0\n",
      "Conv2dStaticSamePadding-15         [-1, 16, 160, 160]             512\n",
      "      BatchNorm2d-16         [-1, 16, 160, 160]              32\n",
      "      MBConvBlock-17         [-1, 16, 160, 160]               0\n",
      "         Identity-18         [-1, 16, 160, 160]               0\n",
      "Conv2dStaticSamePadding-19         [-1, 96, 160, 160]           1,536\n",
      "      BatchNorm2d-20         [-1, 96, 160, 160]             192\n",
      "MemoryEfficientSwish-21         [-1, 96, 160, 160]               0\n",
      "        ZeroPad2d-22         [-1, 96, 161, 161]               0\n",
      "Conv2dStaticSamePadding-23           [-1, 96, 80, 80]             864\n",
      "      BatchNorm2d-24           [-1, 96, 80, 80]             192\n",
      "MemoryEfficientSwish-25           [-1, 96, 80, 80]               0\n",
      "         Identity-26             [-1, 96, 1, 1]               0\n",
      "Conv2dStaticSamePadding-27              [-1, 4, 1, 1]             388\n",
      "MemoryEfficientSwish-28              [-1, 4, 1, 1]               0\n",
      "         Identity-29              [-1, 4, 1, 1]               0\n",
      "Conv2dStaticSamePadding-30             [-1, 96, 1, 1]             480\n",
      "         Identity-31           [-1, 96, 80, 80]               0\n",
      "Conv2dStaticSamePadding-32           [-1, 24, 80, 80]           2,304\n",
      "      BatchNorm2d-33           [-1, 24, 80, 80]              48\n",
      "      MBConvBlock-34           [-1, 24, 80, 80]               0\n",
      "         Identity-35           [-1, 24, 80, 80]               0\n",
      "Conv2dStaticSamePadding-36          [-1, 144, 80, 80]           3,456\n",
      "      BatchNorm2d-37          [-1, 144, 80, 80]             288\n",
      "MemoryEfficientSwish-38          [-1, 144, 80, 80]               0\n",
      "        ZeroPad2d-39          [-1, 144, 82, 82]               0\n",
      "Conv2dStaticSamePadding-40          [-1, 144, 80, 80]           1,296\n",
      "      BatchNorm2d-41          [-1, 144, 80, 80]             288\n",
      "MemoryEfficientSwish-42          [-1, 144, 80, 80]               0\n",
      "         Identity-43            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-44              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-45              [-1, 6, 1, 1]               0\n",
      "         Identity-46              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-47            [-1, 144, 1, 1]           1,008\n",
      "         Identity-48          [-1, 144, 80, 80]               0\n",
      "Conv2dStaticSamePadding-49           [-1, 24, 80, 80]           3,456\n",
      "      BatchNorm2d-50           [-1, 24, 80, 80]              48\n",
      "      MBConvBlock-51           [-1, 24, 80, 80]               0\n",
      "         Identity-52           [-1, 24, 80, 80]               0\n",
      "Conv2dStaticSamePadding-53          [-1, 144, 80, 80]           3,456\n",
      "      BatchNorm2d-54          [-1, 144, 80, 80]             288\n",
      "MemoryEfficientSwish-55          [-1, 144, 80, 80]               0\n",
      "        ZeroPad2d-56          [-1, 144, 83, 83]               0\n",
      "Conv2dStaticSamePadding-57          [-1, 144, 40, 40]           3,600\n",
      "      BatchNorm2d-58          [-1, 144, 40, 40]             288\n",
      "MemoryEfficientSwish-59          [-1, 144, 40, 40]               0\n",
      "         Identity-60            [-1, 144, 1, 1]               0\n",
      "Conv2dStaticSamePadding-61              [-1, 6, 1, 1]             870\n",
      "MemoryEfficientSwish-62              [-1, 6, 1, 1]               0\n",
      "         Identity-63              [-1, 6, 1, 1]               0\n",
      "Conv2dStaticSamePadding-64            [-1, 144, 1, 1]           1,008\n",
      "         Identity-65          [-1, 144, 40, 40]               0\n",
      "Conv2dStaticSamePadding-66           [-1, 40, 40, 40]           5,760\n",
      "      BatchNorm2d-67           [-1, 40, 40, 40]              80\n",
      "      MBConvBlock-68           [-1, 40, 40, 40]               0\n",
      "         Identity-69           [-1, 40, 40, 40]               0\n",
      "Conv2dStaticSamePadding-70          [-1, 240, 40, 40]           9,600\n",
      "      BatchNorm2d-71          [-1, 240, 40, 40]             480\n",
      "MemoryEfficientSwish-72          [-1, 240, 40, 40]               0\n",
      "        ZeroPad2d-73          [-1, 240, 44, 44]               0\n",
      "Conv2dStaticSamePadding-74          [-1, 240, 40, 40]           6,000\n",
      "      BatchNorm2d-75          [-1, 240, 40, 40]             480\n",
      "MemoryEfficientSwish-76          [-1, 240, 40, 40]               0\n",
      "         Identity-77            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-78             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-79             [-1, 10, 1, 1]               0\n",
      "         Identity-80             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-81            [-1, 240, 1, 1]           2,640\n",
      "         Identity-82          [-1, 240, 40, 40]               0\n",
      "Conv2dStaticSamePadding-83           [-1, 40, 40, 40]           9,600\n",
      "      BatchNorm2d-84           [-1, 40, 40, 40]              80\n",
      "      MBConvBlock-85           [-1, 40, 40, 40]               0\n",
      "         Identity-86           [-1, 40, 40, 40]               0\n",
      "Conv2dStaticSamePadding-87          [-1, 240, 40, 40]           9,600\n",
      "      BatchNorm2d-88          [-1, 240, 40, 40]             480\n",
      "MemoryEfficientSwish-89          [-1, 240, 40, 40]               0\n",
      "        ZeroPad2d-90          [-1, 240, 41, 41]               0\n",
      "Conv2dStaticSamePadding-91          [-1, 240, 20, 20]           2,160\n",
      "      BatchNorm2d-92          [-1, 240, 20, 20]             480\n",
      "MemoryEfficientSwish-93          [-1, 240, 20, 20]               0\n",
      "         Identity-94            [-1, 240, 1, 1]               0\n",
      "Conv2dStaticSamePadding-95             [-1, 10, 1, 1]           2,410\n",
      "MemoryEfficientSwish-96             [-1, 10, 1, 1]               0\n",
      "         Identity-97             [-1, 10, 1, 1]               0\n",
      "Conv2dStaticSamePadding-98            [-1, 240, 1, 1]           2,640\n",
      "         Identity-99          [-1, 240, 20, 20]               0\n",
      "Conv2dStaticSamePadding-100           [-1, 80, 20, 20]          19,200\n",
      "     BatchNorm2d-101           [-1, 80, 20, 20]             160\n",
      "     MBConvBlock-102           [-1, 80, 20, 20]               0\n",
      "        Identity-103           [-1, 80, 20, 20]               0\n",
      "Conv2dStaticSamePadding-104          [-1, 480, 20, 20]          38,400\n",
      "     BatchNorm2d-105          [-1, 480, 20, 20]             960\n",
      "MemoryEfficientSwish-106          [-1, 480, 20, 20]               0\n",
      "       ZeroPad2d-107          [-1, 480, 22, 22]               0\n",
      "Conv2dStaticSamePadding-108          [-1, 480, 20, 20]           4,320\n",
      "     BatchNorm2d-109          [-1, 480, 20, 20]             960\n",
      "MemoryEfficientSwish-110          [-1, 480, 20, 20]               0\n",
      "        Identity-111            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-112             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-113             [-1, 20, 1, 1]               0\n",
      "        Identity-114             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-115            [-1, 480, 1, 1]          10,080\n",
      "        Identity-116          [-1, 480, 20, 20]               0\n",
      "Conv2dStaticSamePadding-117           [-1, 80, 20, 20]          38,400\n",
      "     BatchNorm2d-118           [-1, 80, 20, 20]             160\n",
      "     MBConvBlock-119           [-1, 80, 20, 20]               0\n",
      "        Identity-120           [-1, 80, 20, 20]               0\n",
      "Conv2dStaticSamePadding-121          [-1, 480, 20, 20]          38,400\n",
      "     BatchNorm2d-122          [-1, 480, 20, 20]             960\n",
      "MemoryEfficientSwish-123          [-1, 480, 20, 20]               0\n",
      "       ZeroPad2d-124          [-1, 480, 22, 22]               0\n",
      "Conv2dStaticSamePadding-125          [-1, 480, 20, 20]           4,320\n",
      "     BatchNorm2d-126          [-1, 480, 20, 20]             960\n",
      "MemoryEfficientSwish-127          [-1, 480, 20, 20]               0\n",
      "        Identity-128            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-129             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-130             [-1, 20, 1, 1]               0\n",
      "        Identity-131             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-132            [-1, 480, 1, 1]          10,080\n",
      "        Identity-133          [-1, 480, 20, 20]               0\n",
      "Conv2dStaticSamePadding-134           [-1, 80, 20, 20]          38,400\n",
      "     BatchNorm2d-135           [-1, 80, 20, 20]             160\n",
      "     MBConvBlock-136           [-1, 80, 20, 20]               0\n",
      "        Identity-137           [-1, 80, 20, 20]               0\n",
      "Conv2dStaticSamePadding-138          [-1, 480, 20, 20]          38,400\n",
      "     BatchNorm2d-139          [-1, 480, 20, 20]             960\n",
      "MemoryEfficientSwish-140          [-1, 480, 20, 20]               0\n",
      "       ZeroPad2d-141          [-1, 480, 24, 24]               0\n",
      "Conv2dStaticSamePadding-142          [-1, 480, 20, 20]          12,000\n",
      "     BatchNorm2d-143          [-1, 480, 20, 20]             960\n",
      "MemoryEfficientSwish-144          [-1, 480, 20, 20]               0\n",
      "        Identity-145            [-1, 480, 1, 1]               0\n",
      "Conv2dStaticSamePadding-146             [-1, 20, 1, 1]           9,620\n",
      "MemoryEfficientSwish-147             [-1, 20, 1, 1]               0\n",
      "        Identity-148             [-1, 20, 1, 1]               0\n",
      "Conv2dStaticSamePadding-149            [-1, 480, 1, 1]          10,080\n",
      "        Identity-150          [-1, 480, 20, 20]               0\n",
      "Conv2dStaticSamePadding-151          [-1, 112, 20, 20]          53,760\n",
      "     BatchNorm2d-152          [-1, 112, 20, 20]             224\n",
      "     MBConvBlock-153          [-1, 112, 20, 20]               0\n",
      "        Identity-154          [-1, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-155          [-1, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-156          [-1, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-157          [-1, 672, 20, 20]               0\n",
      "       ZeroPad2d-158          [-1, 672, 24, 24]               0\n",
      "Conv2dStaticSamePadding-159          [-1, 672, 20, 20]          16,800\n",
      "     BatchNorm2d-160          [-1, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-161          [-1, 672, 20, 20]               0\n",
      "        Identity-162            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-163             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-164             [-1, 28, 1, 1]               0\n",
      "        Identity-165             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-166            [-1, 672, 1, 1]          19,488\n",
      "        Identity-167          [-1, 672, 20, 20]               0\n",
      "Conv2dStaticSamePadding-168          [-1, 112, 20, 20]          75,264\n",
      "     BatchNorm2d-169          [-1, 112, 20, 20]             224\n",
      "     MBConvBlock-170          [-1, 112, 20, 20]               0\n",
      "        Identity-171          [-1, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-172          [-1, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-173          [-1, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-174          [-1, 672, 20, 20]               0\n",
      "       ZeroPad2d-175          [-1, 672, 24, 24]               0\n",
      "Conv2dStaticSamePadding-176          [-1, 672, 20, 20]          16,800\n",
      "     BatchNorm2d-177          [-1, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-178          [-1, 672, 20, 20]               0\n",
      "        Identity-179            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-180             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-181             [-1, 28, 1, 1]               0\n",
      "        Identity-182             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-183            [-1, 672, 1, 1]          19,488\n",
      "        Identity-184          [-1, 672, 20, 20]               0\n",
      "Conv2dStaticSamePadding-185          [-1, 112, 20, 20]          75,264\n",
      "     BatchNorm2d-186          [-1, 112, 20, 20]             224\n",
      "     MBConvBlock-187          [-1, 112, 20, 20]               0\n",
      "        Identity-188          [-1, 112, 20, 20]               0\n",
      "Conv2dStaticSamePadding-189          [-1, 672, 20, 20]          75,264\n",
      "     BatchNorm2d-190          [-1, 672, 20, 20]           1,344\n",
      "MemoryEfficientSwish-191          [-1, 672, 20, 20]               0\n",
      "       ZeroPad2d-192          [-1, 672, 23, 23]               0\n",
      "Conv2dStaticSamePadding-193          [-1, 672, 10, 10]          16,800\n",
      "     BatchNorm2d-194          [-1, 672, 10, 10]           1,344\n",
      "MemoryEfficientSwish-195          [-1, 672, 10, 10]               0\n",
      "        Identity-196            [-1, 672, 1, 1]               0\n",
      "Conv2dStaticSamePadding-197             [-1, 28, 1, 1]          18,844\n",
      "MemoryEfficientSwish-198             [-1, 28, 1, 1]               0\n",
      "        Identity-199             [-1, 28, 1, 1]               0\n",
      "Conv2dStaticSamePadding-200            [-1, 672, 1, 1]          19,488\n",
      "        Identity-201          [-1, 672, 10, 10]               0\n",
      "Conv2dStaticSamePadding-202          [-1, 192, 10, 10]         129,024\n",
      "     BatchNorm2d-203          [-1, 192, 10, 10]             384\n",
      "     MBConvBlock-204          [-1, 192, 10, 10]               0\n",
      "        Identity-205          [-1, 192, 10, 10]               0\n",
      "Conv2dStaticSamePadding-206         [-1, 1152, 10, 10]         221,184\n",
      "     BatchNorm2d-207         [-1, 1152, 10, 10]           2,304\n",
      "MemoryEfficientSwish-208         [-1, 1152, 10, 10]               0\n",
      "       ZeroPad2d-209         [-1, 1152, 14, 14]               0\n",
      "Conv2dStaticSamePadding-210         [-1, 1152, 10, 10]          28,800\n",
      "     BatchNorm2d-211         [-1, 1152, 10, 10]           2,304\n",
      "MemoryEfficientSwish-212         [-1, 1152, 10, 10]               0\n",
      "        Identity-213           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-214             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-215             [-1, 48, 1, 1]               0\n",
      "        Identity-216             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-217           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-218         [-1, 1152, 10, 10]               0\n",
      "Conv2dStaticSamePadding-219          [-1, 192, 10, 10]         221,184\n",
      "     BatchNorm2d-220          [-1, 192, 10, 10]             384\n",
      "     MBConvBlock-221          [-1, 192, 10, 10]               0\n",
      "        Identity-222          [-1, 192, 10, 10]               0\n",
      "Conv2dStaticSamePadding-223         [-1, 1152, 10, 10]         221,184\n",
      "     BatchNorm2d-224         [-1, 1152, 10, 10]           2,304\n",
      "MemoryEfficientSwish-225         [-1, 1152, 10, 10]               0\n",
      "       ZeroPad2d-226         [-1, 1152, 14, 14]               0\n",
      "Conv2dStaticSamePadding-227         [-1, 1152, 10, 10]          28,800\n",
      "     BatchNorm2d-228         [-1, 1152, 10, 10]           2,304\n",
      "MemoryEfficientSwish-229         [-1, 1152, 10, 10]               0\n",
      "        Identity-230           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-231             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-232             [-1, 48, 1, 1]               0\n",
      "        Identity-233             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-234           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-235         [-1, 1152, 10, 10]               0\n",
      "Conv2dStaticSamePadding-236          [-1, 192, 10, 10]         221,184\n",
      "     BatchNorm2d-237          [-1, 192, 10, 10]             384\n",
      "     MBConvBlock-238          [-1, 192, 10, 10]               0\n",
      "        Identity-239          [-1, 192, 10, 10]               0\n",
      "Conv2dStaticSamePadding-240         [-1, 1152, 10, 10]         221,184\n",
      "     BatchNorm2d-241         [-1, 1152, 10, 10]           2,304\n",
      "MemoryEfficientSwish-242         [-1, 1152, 10, 10]               0\n",
      "       ZeroPad2d-243         [-1, 1152, 14, 14]               0\n",
      "Conv2dStaticSamePadding-244         [-1, 1152, 10, 10]          28,800\n",
      "     BatchNorm2d-245         [-1, 1152, 10, 10]           2,304\n",
      "MemoryEfficientSwish-246         [-1, 1152, 10, 10]               0\n",
      "        Identity-247           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-248             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-249             [-1, 48, 1, 1]               0\n",
      "        Identity-250             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-251           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-252         [-1, 1152, 10, 10]               0\n",
      "Conv2dStaticSamePadding-253          [-1, 192, 10, 10]         221,184\n",
      "     BatchNorm2d-254          [-1, 192, 10, 10]             384\n",
      "     MBConvBlock-255          [-1, 192, 10, 10]               0\n",
      "        Identity-256          [-1, 192, 10, 10]               0\n",
      "Conv2dStaticSamePadding-257         [-1, 1152, 10, 10]         221,184\n",
      "     BatchNorm2d-258         [-1, 1152, 10, 10]           2,304\n",
      "MemoryEfficientSwish-259         [-1, 1152, 10, 10]               0\n",
      "       ZeroPad2d-260         [-1, 1152, 12, 12]               0\n",
      "Conv2dStaticSamePadding-261         [-1, 1152, 10, 10]          10,368\n",
      "     BatchNorm2d-262         [-1, 1152, 10, 10]           2,304\n",
      "MemoryEfficientSwish-263         [-1, 1152, 10, 10]               0\n",
      "        Identity-264           [-1, 1152, 1, 1]               0\n",
      "Conv2dStaticSamePadding-265             [-1, 48, 1, 1]          55,344\n",
      "MemoryEfficientSwish-266             [-1, 48, 1, 1]               0\n",
      "        Identity-267             [-1, 48, 1, 1]               0\n",
      "Conv2dStaticSamePadding-268           [-1, 1152, 1, 1]          56,448\n",
      "        Identity-269         [-1, 1152, 10, 10]               0\n",
      "Conv2dStaticSamePadding-270          [-1, 320, 10, 10]         368,640\n",
      "     BatchNorm2d-271          [-1, 320, 10, 10]             640\n",
      "     MBConvBlock-272          [-1, 320, 10, 10]               0\n",
      "        Identity-273          [-1, 320, 10, 10]               0\n",
      "Conv2dStaticSamePadding-274         [-1, 1280, 10, 10]         409,600\n",
      "     BatchNorm2d-275         [-1, 1280, 10, 10]           2,560\n",
      "MemoryEfficientSwish-276         [-1, 1280, 10, 10]               0\n",
      "AdaptiveAvgPool2d-277           [-1, 1280, 1, 1]               0\n",
      "         Dropout-278                 [-1, 1280]               0\n",
      "          Linear-279                 [-1, 1000]       1,281,000\n",
      "================================================================\n",
      "Total params: 5,288,548\n",
      "Trainable params: 5,288,548\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.17\n",
      "Forward/backward pass size (MB): 429.88\n",
      "Params size (MB): 20.17\n",
      "Estimated Total Size (MB): 451.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.to('cuda'),input_size=(3, 320, 320))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel_1",
   "language": "python",
   "name": "harsimar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
